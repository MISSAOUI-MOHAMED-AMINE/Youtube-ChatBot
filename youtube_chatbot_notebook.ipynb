{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "5aab7911-2a0b-4a5c-bb88-1fc97e086455",
    "_uuid": "9a648608-7b5f-4097-8a28-2269a25e360d",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-11-18T17:30:55.997305Z",
     "iopub.status.busy": "2024-11-18T17:30:55.993957Z",
     "iopub.status.idle": "2024-11-18T17:33:01.636231Z",
     "shell.execute_reply": "2024-11-18T17:33:01.634722Z",
     "shell.execute_reply.started": "2024-11-18T17:30:55.997214Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain==0.2.1\n",
      "  Downloading langchain-0.2.1-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /opt/conda/lib/python3.10/site-packages (from langchain==0.2.1) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/conda/lib/python3.10/site-packages (from langchain==0.2.1) (2.0.30)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /opt/conda/lib/python3.10/site-packages (from langchain==0.2.1) (3.9.5)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /opt/conda/lib/python3.10/site-packages (from langchain==0.2.1) (4.0.3)\n",
      "Collecting langchain-core<0.3.0,>=0.2.0 (from langchain==0.2.1)\n",
      "  Downloading langchain_core-0.2.43-py3-none-any.whl.metadata (6.2 kB)\n",
      "Collecting langchain-text-splitters<0.3.0,>=0.2.0 (from langchain==0.2.1)\n",
      "  Downloading langchain_text_splitters-0.2.4-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting langsmith<0.2.0,>=0.1.17 (from langchain==0.2.1)\n",
      "  Downloading langsmith-0.1.143-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy<2,>=1 in /opt/conda/lib/python3.10/site-packages (from langchain==0.2.1) (1.26.4)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /opt/conda/lib/python3.10/site-packages (from langchain==0.2.1) (2.9.2)\n",
      "Requirement already satisfied: requests<3,>=2 in /opt/conda/lib/python3.10/site-packages (from langchain==0.2.1) (2.32.3)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /opt/conda/lib/python3.10/site-packages (from langchain==0.2.1) (8.3.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.2.1) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.2.1) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.2.1) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.2.1) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.2.1) (1.9.4)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.3.0,>=0.2.0->langchain==0.2.1) (1.33)\n",
      "Collecting packaging<25,>=23.2 (from langchain-core<0.3.0,>=0.2.0->langchain==0.2.1)\n",
      "  Downloading packaging-24.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.3.0,>=0.2.0->langchain==0.2.1) (4.12.2)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.17->langchain==0.2.1) (0.27.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /opt/conda/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.17->langchain==0.2.1) (3.10.4)\n",
      "Collecting requests-toolbelt<2.0.0,>=1.0.0 (from langsmith<0.2.0,>=0.1.17->langchain==0.2.1)\n",
      "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1->langchain==0.2.1) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1->langchain==0.2.1) (2.23.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain==0.2.1) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain==0.2.1) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain==0.2.1) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain==0.2.1) (2024.8.30)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain==0.2.1) (3.0.3)\n",
      "Requirement already satisfied: anyio in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain==0.2.1) (4.4.0)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain==0.2.1) (1.0.5)\n",
      "Requirement already satisfied: sniffio in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain==0.2.1) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain==0.2.1) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/conda/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.0->langchain==0.2.1) (2.4)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /opt/conda/lib/python3.10/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain==0.2.1) (1.2.0)\n",
      "Downloading langchain-0.2.1-py3-none-any.whl (973 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m973.5/973.5 kB\u001b[0m \u001b[31m26.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading langchain_core-0.2.43-py3-none-any.whl (397 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m397.1/397.1 kB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langchain_text_splitters-0.2.4-py3-none-any.whl (25 kB)\n",
      "Downloading langsmith-0.1.143-py3-none-any.whl (306 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.0/307.0 kB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading packaging-24.2-py3-none-any.whl (65 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.5/65.5 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: packaging, requests-toolbelt, langsmith, langchain-core, langchain-text-splitters, langchain\n",
      "  Attempting uninstall: packaging\n",
      "    Found existing installation: packaging 21.3\n",
      "    Uninstalling packaging-21.3:\n",
      "      Successfully uninstalled packaging-21.3\n",
      "  Attempting uninstall: requests-toolbelt\n",
      "    Found existing installation: requests-toolbelt 0.10.1\n",
      "    Uninstalling requests-toolbelt-0.10.1:\n",
      "      Successfully uninstalled requests-toolbelt-0.10.1\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "google-cloud-bigquery 2.34.4 requires packaging<22.0dev,>=14.3, but you have packaging 24.2 which is incompatible.\n",
      "jupyterlab 4.2.5 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\n",
      "jupyterlab-lsp 5.1.0 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\n",
      "kfp 2.5.0 requires google-cloud-storage<3,>=2.2.1, but you have google-cloud-storage 1.44.0 which is incompatible.\n",
      "kfp 2.5.0 requires requests-toolbelt<1,>=0.8.0, but you have requests-toolbelt 1.0.0 which is incompatible.\n",
      "libpysal 4.9.2 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\n",
      "thinc 8.3.2 requires numpy<2.1.0,>=2.0.0; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
      "ydata-profiling 4.10.0 requires scipy<1.14,>=1.4.1, but you have scipy 1.14.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed langchain-0.2.1 langchain-core-0.2.43 langchain-text-splitters-0.2.4 langsmith-0.1.143 packaging-24.2 requests-toolbelt-1.0.0\n",
      "Collecting yt_dlp==2024.4.9\n",
      "  Downloading yt_dlp-2024.4.9-py3-none-any.whl.metadata (165 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: brotli in /opt/conda/lib/python3.10/site-packages (from yt_dlp==2024.4.9) (1.1.0)\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.10/site-packages (from yt_dlp==2024.4.9) (2024.8.30)\n",
      "Collecting mutagen (from yt_dlp==2024.4.9)\n",
      "  Downloading mutagen-1.47.0-py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting pycryptodomex (from yt_dlp==2024.4.9)\n",
      "  Downloading pycryptodomex-3.21.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.4 kB)\n",
      "Requirement already satisfied: requests<3,>=2.31.0 in /opt/conda/lib/python3.10/site-packages (from yt_dlp==2024.4.9) (2.32.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.26.17 in /opt/conda/lib/python3.10/site-packages (from yt_dlp==2024.4.9) (1.26.18)\n",
      "Requirement already satisfied: websockets>=12.0 in /opt/conda/lib/python3.10/site-packages (from yt_dlp==2024.4.9) (12.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.31.0->yt_dlp==2024.4.9) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.31.0->yt_dlp==2024.4.9) (3.7)\n",
      "Downloading yt_dlp-2024.4.9-py3-none-any.whl (3.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m0m\n",
      "\u001b[?25hDownloading mutagen-1.47.0-py3-none-any.whl (194 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.4/194.4 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pycryptodomex-3.21.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m58.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pycryptodomex, mutagen, yt_dlp\n",
      "Successfully installed mutagen-1.47.0 pycryptodomex-3.21.0 yt_dlp-2024.4.9\n",
      "Collecting tiktoken==0.6.0\n",
      "  Downloading tiktoken-0.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /opt/conda/lib/python3.10/site-packages (from tiktoken==0.6.0) (2024.5.15)\n",
      "Requirement already satisfied: requests>=2.26.0 in /opt/conda/lib/python3.10/site-packages (from tiktoken==0.6.0) (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken==0.6.0) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken==0.6.0) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken==0.6.0) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken==0.6.0) (2024.8.30)\n",
      "Downloading tiktoken-0.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m30.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: tiktoken\n",
      "Successfully installed tiktoken-0.6.0\n",
      "Collecting docarray==0.40.0\n",
      "  Downloading docarray-0.40.0-py3-none-any.whl.metadata (36 kB)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /opt/conda/lib/python3.10/site-packages (from docarray==0.40.0) (1.26.4)\n",
      "Requirement already satisfied: orjson>=3.8.2 in /opt/conda/lib/python3.10/site-packages (from docarray==0.40.0) (3.10.4)\n",
      "Requirement already satisfied: pydantic>=1.10.8 in /opt/conda/lib/python3.10/site-packages (from docarray==0.40.0) (2.9.2)\n",
      "Requirement already satisfied: rich>=13.1.0 in /opt/conda/lib/python3.10/site-packages (from docarray==0.40.0) (13.7.1)\n",
      "Collecting types-requests>=2.28.11.6 (from docarray==0.40.0)\n",
      "  Downloading types_requests-2.32.0.20241016-py3-none-any.whl.metadata (1.9 kB)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in /opt/conda/lib/python3.10/site-packages (from docarray==0.40.0) (0.9.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from pydantic>=1.10.8->docarray==0.40.0) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /opt/conda/lib/python3.10/site-packages (from pydantic>=1.10.8->docarray==0.40.0) (2.23.4)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /opt/conda/lib/python3.10/site-packages (from pydantic>=1.10.8->docarray==0.40.0) (4.12.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich>=13.1.0->docarray==0.40.0) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich>=13.1.0->docarray==0.40.0) (2.18.0)\n",
      "Collecting urllib3>=2 (from types-requests>=2.28.11.6->docarray==0.40.0)\n",
      "  Downloading urllib3-2.2.3-py3-none-any.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from typing-inspect>=0.8.0->docarray==0.40.0) (1.0.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=13.1.0->docarray==0.40.0) (0.1.2)\n",
      "Downloading docarray-0.40.0-py3-none-any.whl (270 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m270.2/270.2 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading types_requests-2.32.0.20241016-py3-none-any.whl (15 kB)\n",
      "Downloading urllib3-2.2.3-py3-none-any.whl (126 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.3/126.3 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: urllib3, types-requests, docarray\n",
      "  Attempting uninstall: urllib3\n",
      "    Found existing installation: urllib3 1.26.18\n",
      "    Uninstalling urllib3-1.26.18:\n",
      "      Successfully uninstalled urllib3-1.26.18\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "kfp 2.5.0 requires google-cloud-storage<3,>=2.2.1, but you have google-cloud-storage 1.44.0 which is incompatible.\n",
      "kfp 2.5.0 requires requests-toolbelt<1,>=0.8.0, but you have requests-toolbelt 1.0.0 which is incompatible.\n",
      "kfp 2.5.0 requires urllib3<2.0.0, but you have urllib3 2.2.3 which is incompatible.\n",
      "ydata-profiling 4.10.0 requires scipy<1.14,>=1.4.1, but you have scipy 1.14.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed docarray-0.40.0 types-requests-2.32.0.20241016 urllib3-2.2.1\n",
      "\u001b[33mWARNING: Skipping whisper as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting git+https://github.com/openai/whisper.git\n",
      "  Cloning https://github.com/openai/whisper.git to /tmp/pip-req-build-ftbi62yk\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/openai/whisper.git /tmp/pip-req-build-ftbi62yk\n",
      "  Resolved https://github.com/openai/whisper.git to commit 173ff7dd1d9fb1c4fddea0d41d704cfefeb8908c\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: numba in /opt/conda/lib/python3.10/site-packages (from openai-whisper==20240930) (0.60.0)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from openai-whisper==20240930) (1.26.4)\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from openai-whisper==20240930) (2.4.0+cpu)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from openai-whisper==20240930) (4.66.4)\n",
      "Requirement already satisfied: more-itertools in /opt/conda/lib/python3.10/site-packages (from openai-whisper==20240930) (10.3.0)\n",
      "Requirement already satisfied: tiktoken in /opt/conda/lib/python3.10/site-packages (from openai-whisper==20240930) (0.6.0)\n",
      "Collecting triton>=2.0.0 (from openai-whisper==20240930)\n",
      "  Downloading triton-3.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.3 kB)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from triton>=2.0.0->openai-whisper==20240930) (3.15.1)\n",
      "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /opt/conda/lib/python3.10/site-packages (from numba->openai-whisper==20240930) (0.43.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /opt/conda/lib/python3.10/site-packages (from tiktoken->openai-whisper==20240930) (2024.5.15)\n",
      "Requirement already satisfied: requests>=2.26.0 in /opt/conda/lib/python3.10/site-packages (from tiktoken->openai-whisper==20240930) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch->openai-whisper==20240930) (4.12.2)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->openai-whisper==20240930) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->openai-whisper==20240930) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->openai-whisper==20240930) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch->openai-whisper==20240930) (2024.6.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken->openai-whisper==20240930) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken->openai-whisper==20240930) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken->openai-whisper==20240930) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken->openai-whisper==20240930) (2024.8.30)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->openai-whisper==20240930) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->openai-whisper==20240930) (1.3.0)\n",
      "Downloading triton-3.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (209.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.5/209.5 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: openai-whisper\n",
      "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for openai-whisper: filename=openai_whisper-20240930-py3-none-any.whl size=803557 sha256=2fcb01a94de55a13f654b4ba5f71a9d553cec23a0033c2a1b1de229d3995ec34\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-ms5qahjo/wheels/8b/6c/d0/622666868c179f156cf595c8b6f06f88bc5d80c4b31dccaa03\n",
      "Successfully built openai-whisper\n",
      "Installing collected packages: triton, openai-whisper\n",
      "Successfully installed openai-whisper-20240930 triton-3.1.0\n",
      "Collecting langchain_cohere\n",
      "  Downloading langchain_cohere-0.3.1-py3-none-any.whl.metadata (6.7 kB)\n",
      "Collecting cohere<6.0,>=5.5.6 (from langchain_cohere)\n",
      "  Downloading cohere-5.11.4-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting langchain-core<0.4,>=0.3.0 (from langchain_cohere)\n",
      "  Downloading langchain_core-0.3.19-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting langchain-experimental>=0.3.0 (from langchain_cohere)\n",
      "  Downloading langchain_experimental-0.3.3-py3-none-any.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: pandas>=1.4.3 in /opt/conda/lib/python3.10/site-packages (from langchain_cohere) (2.2.3)\n",
      "Requirement already satisfied: pydantic<3,>=2 in /opt/conda/lib/python3.10/site-packages (from langchain_cohere) (2.9.2)\n",
      "Requirement already satisfied: tabulate<0.10.0,>=0.9.0 in /opt/conda/lib/python3.10/site-packages (from langchain_cohere) (0.9.0)\n",
      "Requirement already satisfied: fastavro<2.0.0,>=1.9.4 in /opt/conda/lib/python3.10/site-packages (from cohere<6.0,>=5.5.6->langchain_cohere) (1.9.4)\n",
      "Requirement already satisfied: httpx>=0.21.2 in /opt/conda/lib/python3.10/site-packages (from cohere<6.0,>=5.5.6->langchain_cohere) (0.27.0)\n",
      "Collecting httpx-sse==0.4.0 (from cohere<6.0,>=5.5.6->langchain_cohere)\n",
      "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
      "Collecting parameterized<0.10.0,>=0.9.0 (from cohere<6.0,>=5.5.6->langchain_cohere)\n",
      "  Downloading parameterized-0.9.0-py2.py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: pydantic-core<3.0.0,>=2.18.2 in /opt/conda/lib/python3.10/site-packages (from cohere<6.0,>=5.5.6->langchain_cohere) (2.23.4)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from cohere<6.0,>=5.5.6->langchain_cohere) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<1,>=0.15 in /opt/conda/lib/python3.10/site-packages (from cohere<6.0,>=5.5.6->langchain_cohere) (0.20.0)\n",
      "Requirement already satisfied: types-requests<3.0.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from cohere<6.0,>=5.5.6->langchain_cohere) (2.32.0.20241016)\n",
      "Requirement already satisfied: typing_extensions>=4.0.0 in /opt/conda/lib/python3.10/site-packages (from cohere<6.0,>=5.5.6->langchain_cohere) (4.12.2)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.4,>=0.3.0->langchain_cohere) (6.0.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.4,>=0.3.0->langchain_cohere) (1.33)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.125 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.4,>=0.3.0->langchain_cohere) (0.1.143)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.4,>=0.3.0->langchain_cohere) (24.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.4,>=0.3.0->langchain_cohere) (8.3.0)\n",
      "Collecting langchain-community<0.4.0,>=0.3.0 (from langchain-experimental>=0.3.0->langchain_cohere)\n",
      "  Downloading langchain_community-0.3.7-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: numpy>=1.22.4 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.4.3->langchain_cohere) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.4.3->langchain_cohere) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.4.3->langchain_cohere) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.4.3->langchain_cohere) (2024.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=2->langchain_cohere) (0.7.0)\n",
      "Requirement already satisfied: anyio in /opt/conda/lib/python3.10/site-packages (from httpx>=0.21.2->cohere<6.0,>=5.5.6->langchain_cohere) (4.4.0)\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.10/site-packages (from httpx>=0.21.2->cohere<6.0,>=5.5.6->langchain_cohere) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.10/site-packages (from httpx>=0.21.2->cohere<6.0,>=5.5.6->langchain_cohere) (1.0.5)\n",
      "Requirement already satisfied: idna in /opt/conda/lib/python3.10/site-packages (from httpx>=0.21.2->cohere<6.0,>=5.5.6->langchain_cohere) (3.7)\n",
      "Requirement already satisfied: sniffio in /opt/conda/lib/python3.10/site-packages (from httpx>=0.21.2->cohere<6.0,>=5.5.6->langchain_cohere) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.10/site-packages (from httpcore==1.*->httpx>=0.21.2->cohere<6.0,>=5.5.6->langchain_cohere) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/conda/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4,>=0.3.0->langchain_cohere) (2.4)\n",
      "Requirement already satisfied: SQLAlchemy<2.0.36,>=1.4 in /opt/conda/lib/python3.10/site-packages (from langchain-community<0.4.0,>=0.3.0->langchain-experimental>=0.3.0->langchain_cohere) (2.0.30)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /opt/conda/lib/python3.10/site-packages (from langchain-community<0.4.0,>=0.3.0->langchain-experimental>=0.3.0->langchain_cohere) (3.9.5)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /opt/conda/lib/python3.10/site-packages (from langchain-community<0.4.0,>=0.3.0->langchain-experimental>=0.3.0->langchain_cohere) (0.6.7)\n",
      "Collecting langchain<0.4.0,>=0.3.7 (from langchain-community<0.4.0,>=0.3.0->langchain-experimental>=0.3.0->langchain_cohere)\n",
      "  Downloading langchain-0.3.7-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community<0.4.0,>=0.3.0->langchain-experimental>=0.3.0->langchain_cohere)\n",
      "  Downloading pydantic_settings-2.6.1-py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /opt/conda/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3.0->langchain_cohere) (3.10.4)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3.0->langchain_cohere) (1.0.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas>=1.4.3->langchain_cohere) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.0.0->cohere<6.0,>=5.5.6->langchain_cohere) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.0.0->cohere<6.0,>=5.5.6->langchain_cohere) (2.2.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /opt/conda/lib/python3.10/site-packages (from tokenizers<1,>=0.15->cohere<6.0,>=5.5.6->langchain_cohere) (0.25.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain-experimental>=0.3.0->langchain_cohere) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain-experimental>=0.3.0->langchain_cohere) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain-experimental>=0.3.0->langchain_cohere) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain-experimental>=0.3.0->langchain_cohere) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain-experimental>=0.3.0->langchain_cohere) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain-experimental>=0.3.0->langchain_cohere) (4.0.3)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /opt/conda/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community<0.4.0,>=0.3.0->langchain-experimental>=0.3.0->langchain_cohere) (3.22.0)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community<0.4.0,>=0.3.0->langchain-experimental>=0.3.0->langchain_cohere) (0.9.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere<6.0,>=5.5.6->langchain_cohere) (3.15.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere<6.0,>=5.5.6->langchain_cohere) (2024.6.1)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere<6.0,>=5.5.6->langchain_cohere) (4.66.4)\n",
      "Collecting langchain-text-splitters<0.4.0,>=0.3.0 (from langchain<0.4.0,>=0.3.7->langchain-community<0.4.0,>=0.3.0->langchain-experimental>=0.3.0->langchain_cohere)\n",
      "  Downloading langchain_text_splitters-0.3.2-py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in /opt/conda/lib/python3.10/site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community<0.4.0,>=0.3.0->langchain-experimental>=0.3.0->langchain_cohere) (1.0.1)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from SQLAlchemy<2.0.36,>=1.4->langchain-community<0.4.0,>=0.3.0->langchain-experimental>=0.3.0->langchain_cohere) (3.0.3)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /opt/conda/lib/python3.10/site-packages (from anyio->httpx>=0.21.2->cohere<6.0,>=5.5.6->langchain_cohere) (1.2.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community<0.4.0,>=0.3.0->langchain-experimental>=0.3.0->langchain_cohere) (1.0.0)\n",
      "Downloading langchain_cohere-0.3.1-py3-none-any.whl (43 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.0/44.0 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading cohere-5.11.4-py3-none-any.whl (249 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m249.7/249.7 kB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
      "Downloading langchain_core-0.3.19-py3-none-any.whl (409 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m409.3/409.3 kB\u001b[0m \u001b[31m23.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langchain_experimental-0.3.3-py3-none-any.whl (208 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.0/209.0 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langchain_community-0.3.7-py3-none-any.whl (2.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m53.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading parameterized-0.9.0-py2.py3-none-any.whl (20 kB)\n",
      "Downloading langchain-0.3.7-py3-none-any.whl (1.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m39.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pydantic_settings-2.6.1-py3-none-any.whl (28 kB)\n",
      "Downloading langchain_text_splitters-0.3.2-py3-none-any.whl (25 kB)\n",
      "Installing collected packages: parameterized, httpx-sse, pydantic-settings, langchain-core, cohere, langchain-text-splitters, langchain, langchain-community, langchain-experimental, langchain_cohere\n",
      "  Attempting uninstall: langchain-core\n",
      "    Found existing installation: langchain-core 0.2.43\n",
      "    Uninstalling langchain-core-0.2.43:\n",
      "      Successfully uninstalled langchain-core-0.2.43\n",
      "  Attempting uninstall: langchain-text-splitters\n",
      "    Found existing installation: langchain-text-splitters 0.2.4\n",
      "    Uninstalling langchain-text-splitters-0.2.4:\n",
      "      Successfully uninstalled langchain-text-splitters-0.2.4\n",
      "  Attempting uninstall: langchain\n",
      "    Found existing installation: langchain 0.2.1\n",
      "    Uninstalling langchain-0.2.1:\n",
      "      Successfully uninstalled langchain-0.2.1\n",
      "Successfully installed cohere-5.11.4 httpx-sse-0.4.0 langchain-0.3.7 langchain-community-0.3.7 langchain-core-0.3.19 langchain-experimental-0.3.3 langchain-text-splitters-0.3.2 langchain_cohere-0.3.1 parameterized-0.9.0 pydantic-settings-2.6.1\n",
      "Requirement already satisfied: langchain-cohere in /opt/conda/lib/python3.10/site-packages (0.3.1)\n",
      "Requirement already satisfied: cohere<6.0,>=5.5.6 in /opt/conda/lib/python3.10/site-packages (from langchain-cohere) (5.11.4)\n",
      "Requirement already satisfied: langchain-core<0.4,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from langchain-cohere) (0.3.19)\n",
      "Requirement already satisfied: langchain-experimental>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from langchain-cohere) (0.3.3)\n",
      "Requirement already satisfied: pandas>=1.4.3 in /opt/conda/lib/python3.10/site-packages (from langchain-cohere) (2.2.3)\n",
      "Requirement already satisfied: pydantic<3,>=2 in /opt/conda/lib/python3.10/site-packages (from langchain-cohere) (2.9.2)\n",
      "Requirement already satisfied: tabulate<0.10.0,>=0.9.0 in /opt/conda/lib/python3.10/site-packages (from langchain-cohere) (0.9.0)\n",
      "Requirement already satisfied: fastavro<2.0.0,>=1.9.4 in /opt/conda/lib/python3.10/site-packages (from cohere<6.0,>=5.5.6->langchain-cohere) (1.9.4)\n",
      "Requirement already satisfied: httpx>=0.21.2 in /opt/conda/lib/python3.10/site-packages (from cohere<6.0,>=5.5.6->langchain-cohere) (0.27.0)\n",
      "Requirement already satisfied: httpx-sse==0.4.0 in /opt/conda/lib/python3.10/site-packages (from cohere<6.0,>=5.5.6->langchain-cohere) (0.4.0)\n",
      "Requirement already satisfied: parameterized<0.10.0,>=0.9.0 in /opt/conda/lib/python3.10/site-packages (from cohere<6.0,>=5.5.6->langchain-cohere) (0.9.0)\n",
      "Requirement already satisfied: pydantic-core<3.0.0,>=2.18.2 in /opt/conda/lib/python3.10/site-packages (from cohere<6.0,>=5.5.6->langchain-cohere) (2.23.4)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from cohere<6.0,>=5.5.6->langchain-cohere) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<1,>=0.15 in /opt/conda/lib/python3.10/site-packages (from cohere<6.0,>=5.5.6->langchain-cohere) (0.20.0)\n",
      "Requirement already satisfied: types-requests<3.0.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from cohere<6.0,>=5.5.6->langchain-cohere) (2.32.0.20241016)\n",
      "Requirement already satisfied: typing_extensions>=4.0.0 in /opt/conda/lib/python3.10/site-packages (from cohere<6.0,>=5.5.6->langchain-cohere) (4.12.2)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.4,>=0.3.0->langchain-cohere) (6.0.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.4,>=0.3.0->langchain-cohere) (1.33)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.125 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.4,>=0.3.0->langchain-cohere) (0.1.143)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.4,>=0.3.0->langchain-cohere) (24.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.4,>=0.3.0->langchain-cohere) (8.3.0)\n",
      "Requirement already satisfied: langchain-community<0.4.0,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from langchain-experimental>=0.3.0->langchain-cohere) (0.3.7)\n",
      "Requirement already satisfied: numpy>=1.22.4 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.4.3->langchain-cohere) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.4.3->langchain-cohere) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.4.3->langchain-cohere) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.4.3->langchain-cohere) (2024.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=2->langchain-cohere) (0.7.0)\n",
      "Requirement already satisfied: anyio in /opt/conda/lib/python3.10/site-packages (from httpx>=0.21.2->cohere<6.0,>=5.5.6->langchain-cohere) (4.4.0)\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.10/site-packages (from httpx>=0.21.2->cohere<6.0,>=5.5.6->langchain-cohere) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.10/site-packages (from httpx>=0.21.2->cohere<6.0,>=5.5.6->langchain-cohere) (1.0.5)\n",
      "Requirement already satisfied: idna in /opt/conda/lib/python3.10/site-packages (from httpx>=0.21.2->cohere<6.0,>=5.5.6->langchain-cohere) (3.7)\n",
      "Requirement already satisfied: sniffio in /opt/conda/lib/python3.10/site-packages (from httpx>=0.21.2->cohere<6.0,>=5.5.6->langchain-cohere) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.10/site-packages (from httpcore==1.*->httpx>=0.21.2->cohere<6.0,>=5.5.6->langchain-cohere) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/conda/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4,>=0.3.0->langchain-cohere) (2.4)\n",
      "Requirement already satisfied: SQLAlchemy<2.0.36,>=1.4 in /opt/conda/lib/python3.10/site-packages (from langchain-community<0.4.0,>=0.3.0->langchain-experimental>=0.3.0->langchain-cohere) (2.0.30)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /opt/conda/lib/python3.10/site-packages (from langchain-community<0.4.0,>=0.3.0->langchain-experimental>=0.3.0->langchain-cohere) (3.9.5)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /opt/conda/lib/python3.10/site-packages (from langchain-community<0.4.0,>=0.3.0->langchain-experimental>=0.3.0->langchain-cohere) (0.6.7)\n",
      "Requirement already satisfied: langchain<0.4.0,>=0.3.7 in /opt/conda/lib/python3.10/site-packages (from langchain-community<0.4.0,>=0.3.0->langchain-experimental>=0.3.0->langchain-cohere) (0.3.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /opt/conda/lib/python3.10/site-packages (from langchain-community<0.4.0,>=0.3.0->langchain-experimental>=0.3.0->langchain-cohere) (2.6.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /opt/conda/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3.0->langchain-cohere) (3.10.4)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3.0->langchain-cohere) (1.0.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas>=1.4.3->langchain-cohere) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.0.0->cohere<6.0,>=5.5.6->langchain-cohere) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.0.0->cohere<6.0,>=5.5.6->langchain-cohere) (2.2.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /opt/conda/lib/python3.10/site-packages (from tokenizers<1,>=0.15->cohere<6.0,>=5.5.6->langchain-cohere) (0.25.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain-experimental>=0.3.0->langchain-cohere) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain-experimental>=0.3.0->langchain-cohere) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain-experimental>=0.3.0->langchain-cohere) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain-experimental>=0.3.0->langchain-cohere) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain-experimental>=0.3.0->langchain-cohere) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain-experimental>=0.3.0->langchain-cohere) (4.0.3)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /opt/conda/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community<0.4.0,>=0.3.0->langchain-experimental>=0.3.0->langchain-cohere) (3.22.0)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community<0.4.0,>=0.3.0->langchain-experimental>=0.3.0->langchain-cohere) (0.9.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere<6.0,>=5.5.6->langchain-cohere) (3.15.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere<6.0,>=5.5.6->langchain-cohere) (2024.6.1)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere<6.0,>=5.5.6->langchain-cohere) (4.66.4)\n",
      "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from langchain<0.4.0,>=0.3.7->langchain-community<0.4.0,>=0.3.0->langchain-experimental>=0.3.0->langchain-cohere) (0.3.2)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in /opt/conda/lib/python3.10/site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community<0.4.0,>=0.3.0->langchain-experimental>=0.3.0->langchain-cohere) (1.0.1)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from SQLAlchemy<2.0.36,>=1.4->langchain-community<0.4.0,>=0.3.0->langchain-experimental>=0.3.0->langchain-cohere) (3.0.3)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /opt/conda/lib/python3.10/site-packages (from anyio->httpx>=0.21.2->cohere<6.0,>=5.5.6->langchain-cohere) (1.2.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community<0.4.0,>=0.3.0->langchain-experimental>=0.3.0->langchain-cohere) (1.0.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain==0.2.1\n",
    "# Install the yt_dlp package, locked to version 2024.4.9\n",
    "!pip install yt_dlp==2024.4.9\n",
    "\n",
    "# Install the tiktoken package, locked to version 0.6.0\n",
    "!pip install tiktoken==0.6.0\n",
    "\n",
    "# Install the docarray package, locked to version 0.40.0\n",
    "!pip install docarray==0.40.0\n",
    "!pip uninstall whisper\n",
    "!pip install git+https://github.com/openai/whisper.git\n",
    "!pip install langchain_cohere\n",
    "!pip install langchain-cohere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T17:33:01.639495Z",
     "iopub.status.busy": "2024-11-18T17:33:01.639063Z",
     "iopub.status.idle": "2024-11-18T17:33:36.442369Z",
     "shell.execute_reply": "2024-11-18T17:33:36.440770Z",
     "shell.execute_reply.started": "2024-11-18T17:33:01.639452Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting chromadb\n",
      "  Downloading chromadb-0.5.18-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting build>=1.0.3 (from chromadb)\n",
      "  Downloading build-1.2.2.post1-py3-none-any.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: pydantic>=1.9 in /opt/conda/lib/python3.10/site-packages (from chromadb) (2.9.2)\n",
      "Collecting chroma-hnswlib==0.7.6 (from chromadb)\n",
      "  Downloading chroma_hnswlib-0.7.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (252 bytes)\n",
      "Requirement already satisfied: fastapi>=0.95.2 in /opt/conda/lib/python3.10/site-packages (from chromadb) (0.111.0)\n",
      "Requirement already satisfied: uvicorn>=0.18.3 in /opt/conda/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.30.1)\n",
      "Requirement already satisfied: numpy>=1.22.5 in /opt/conda/lib/python3.10/site-packages (from chromadb) (1.26.4)\n",
      "Collecting posthog>=2.4.0 (from chromadb)\n",
      "  Downloading posthog-3.7.0-py2.py3-none-any.whl.metadata (2.0 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /opt/conda/lib/python3.10/site-packages (from chromadb) (4.12.2)\n",
      "Collecting onnxruntime>=1.14.1 (from chromadb)\n",
      "  Downloading onnxruntime-1.20.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.4 kB)\n",
      "Requirement already satisfied: opentelemetry-api>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from chromadb) (1.25.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from chromadb) (1.25.0)\n",
      "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb)\n",
      "  Downloading opentelemetry_instrumentation_fastapi-0.49b1-py3-none-any.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from chromadb) (1.25.0)\n",
      "Requirement already satisfied: tokenizers>=0.13.2 in /opt/conda/lib/python3.10/site-packages (from chromadb) (0.20.0)\n",
      "Collecting pypika>=0.48.9 (from chromadb)\n",
      "  Downloading PyPika-0.48.9.tar.gz (67 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: tqdm>=4.65.0 in /opt/conda/lib/python3.10/site-packages (from chromadb) (4.66.4)\n",
      "Requirement already satisfied: overrides>=7.3.1 in /opt/conda/lib/python3.10/site-packages (from chromadb) (7.7.0)\n",
      "Requirement already satisfied: importlib-resources in /opt/conda/lib/python3.10/site-packages (from chromadb) (6.4.0)\n",
      "Requirement already satisfied: grpcio>=1.58.0 in /opt/conda/lib/python3.10/site-packages (from chromadb) (1.64.1)\n",
      "Collecting bcrypt>=4.0.1 (from chromadb)\n",
      "  Downloading bcrypt-4.2.0-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (9.6 kB)\n",
      "Requirement already satisfied: typer>=0.9.0 in /opt/conda/lib/python3.10/site-packages (from chromadb) (0.12.3)\n",
      "Collecting kubernetes>=28.1.0 (from chromadb)\n",
      "  Downloading kubernetes-31.0.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: tenacity>=8.2.3 in /opt/conda/lib/python3.10/site-packages (from chromadb) (8.3.0)\n",
      "Requirement already satisfied: PyYAML>=6.0.0 in /opt/conda/lib/python3.10/site-packages (from chromadb) (6.0.2)\n",
      "Collecting mmh3>=4.0.1 (from chromadb)\n",
      "  Downloading mmh3-5.0.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\n",
      "Requirement already satisfied: orjson>=3.9.12 in /opt/conda/lib/python3.10/site-packages (from chromadb) (3.10.4)\n",
      "Requirement already satisfied: httpx>=0.27.0 in /opt/conda/lib/python3.10/site-packages (from chromadb) (0.27.0)\n",
      "Requirement already satisfied: rich>=10.11.0 in /opt/conda/lib/python3.10/site-packages (from chromadb) (13.7.1)\n",
      "Requirement already satisfied: packaging>=19.1 in /opt/conda/lib/python3.10/site-packages (from build>=1.0.3->chromadb) (24.2)\n",
      "Collecting pyproject_hooks (from build>=1.0.3->chromadb)\n",
      "  Downloading pyproject_hooks-1.2.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Requirement already satisfied: tomli>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from build>=1.0.3->chromadb) (2.0.1)\n",
      "Requirement already satisfied: starlette<0.38.0,>=0.37.2 in /opt/conda/lib/python3.10/site-packages (from fastapi>=0.95.2->chromadb) (0.37.2)\n",
      "Requirement already satisfied: fastapi-cli>=0.0.2 in /opt/conda/lib/python3.10/site-packages (from fastapi>=0.95.2->chromadb) (0.0.4)\n",
      "Requirement already satisfied: jinja2>=2.11.2 in /opt/conda/lib/python3.10/site-packages (from fastapi>=0.95.2->chromadb) (3.1.4)\n",
      "Requirement already satisfied: python-multipart>=0.0.7 in /opt/conda/lib/python3.10/site-packages (from fastapi>=0.95.2->chromadb) (0.0.9)\n",
      "Requirement already satisfied: ujson!=4.0.2,!=4.1.0,!=4.2.0,!=4.3.0,!=5.0.0,!=5.1.0,>=4.0.1 in /opt/conda/lib/python3.10/site-packages (from fastapi>=0.95.2->chromadb) (5.10.0)\n",
      "Requirement already satisfied: email_validator>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from fastapi>=0.95.2->chromadb) (2.1.1)\n",
      "Requirement already satisfied: anyio in /opt/conda/lib/python3.10/site-packages (from httpx>=0.27.0->chromadb) (4.4.0)\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.10/site-packages (from httpx>=0.27.0->chromadb) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.10/site-packages (from httpx>=0.27.0->chromadb) (1.0.5)\n",
      "Requirement already satisfied: idna in /opt/conda/lib/python3.10/site-packages (from httpx>=0.27.0->chromadb) (3.7)\n",
      "Requirement already satisfied: sniffio in /opt/conda/lib/python3.10/site-packages (from httpx>=0.27.0->chromadb) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.10/site-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.14.0)\n",
      "Requirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in /opt/conda/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb) (2.9.0.post0)\n",
      "Requirement already satisfied: google-auth>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb) (2.30.0)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /opt/conda/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb) (1.8.0)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb) (2.32.3)\n",
      "Requirement already satisfied: requests-oauthlib in /opt/conda/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb) (2.0.0)\n",
      "Requirement already satisfied: oauthlib>=3.2.2 in /opt/conda/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb) (3.2.2)\n",
      "Requirement already satisfied: urllib3>=1.24.2 in /opt/conda/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb) (2.2.1)\n",
      "Collecting durationpy>=0.7 (from kubernetes>=28.1.0->chromadb)\n",
      "  Downloading durationpy-0.9-py3-none-any.whl.metadata (338 bytes)\n",
      "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb)\n",
      "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: flatbuffers in /opt/conda/lib/python3.10/site-packages (from onnxruntime>=1.14.1->chromadb) (24.3.25)\n",
      "Requirement already satisfied: protobuf in /opt/conda/lib/python3.10/site-packages (from onnxruntime>=1.14.1->chromadb) (3.20.3)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from onnxruntime>=1.14.1->chromadb) (1.12)\n",
      "Requirement already satisfied: deprecated>=1.2.6 in /opt/conda/lib/python3.10/site-packages (from opentelemetry-api>=1.2.0->chromadb) (1.2.14)\n",
      "Requirement already satisfied: importlib-metadata<=7.1,>=6.0 in /opt/conda/lib/python3.10/site-packages (from opentelemetry-api>=1.2.0->chromadb) (7.0.0)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.52 in /opt/conda/lib/python3.10/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.63.1)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.25.0 in /opt/conda/lib/python3.10/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.25.0)\n",
      "Requirement already satisfied: opentelemetry-proto==1.25.0 in /opt/conda/lib/python3.10/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.25.0)\n",
      "Collecting opentelemetry-instrumentation-asgi==0.49b1 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Downloading opentelemetry_instrumentation_asgi-0.49b1-py3-none-any.whl.metadata (2.0 kB)\n",
      "Collecting opentelemetry-instrumentation==0.49b1 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Downloading opentelemetry_instrumentation-0.49b1-py3-none-any.whl.metadata (6.2 kB)\n",
      "Collecting opentelemetry-semantic-conventions==0.49b1 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Downloading opentelemetry_semantic_conventions-0.49b1-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting opentelemetry-util-http==0.49b1 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Downloading opentelemetry_util_http-0.49b1-py3-none-any.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from opentelemetry-instrumentation==0.49b1->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (1.16.0)\n",
      "Collecting asgiref~=3.0 (from opentelemetry-instrumentation-asgi==0.49b1->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Downloading asgiref-3.8.1-py3-none-any.whl.metadata (9.3 kB)\n",
      "Collecting opentelemetry-api>=1.2.0 (from chromadb)\n",
      "  Downloading opentelemetry_api-1.28.1-py3-none-any.whl.metadata (1.4 kB)\n",
      "INFO: pip is looking at multiple versions of opentelemetry-sdk to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb)\n",
      "  Downloading opentelemetry_instrumentation_fastapi-0.49b0-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting opentelemetry-instrumentation-asgi==0.49b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Downloading opentelemetry_instrumentation_asgi-0.49b0-py3-none-any.whl.metadata (2.0 kB)\n",
      "Collecting opentelemetry-instrumentation==0.49b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Downloading opentelemetry_instrumentation-0.49b0-py3-none-any.whl.metadata (6.2 kB)\n",
      "Collecting opentelemetry-semantic-conventions==0.49b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Downloading opentelemetry_semantic_conventions-0.49b0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting opentelemetry-util-http==0.49b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Downloading opentelemetry_util_http-0.49b0-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting opentelemetry-api>=1.2.0 (from chromadb)\n",
      "  Downloading opentelemetry_api-1.28.0-py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb)\n",
      "  Downloading opentelemetry_instrumentation_fastapi-0.48b0-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting opentelemetry-instrumentation-asgi==0.48b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Downloading opentelemetry_instrumentation_asgi-0.48b0-py3-none-any.whl.metadata (2.0 kB)\n",
      "Collecting opentelemetry-instrumentation==0.48b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Downloading opentelemetry_instrumentation-0.48b0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting opentelemetry-semantic-conventions==0.48b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Downloading opentelemetry_semantic_conventions-0.48b0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting opentelemetry-util-http==0.48b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Downloading opentelemetry_util_http-0.48b0-py3-none-any.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: setuptools>=16.0 in /opt/conda/lib/python3.10/site-packages (from opentelemetry-instrumentation==0.48b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (70.0.0)\n",
      "Collecting opentelemetry-api>=1.2.0 (from chromadb)\n",
      "  Downloading opentelemetry_api-1.27.0-py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb)\n",
      "  Downloading opentelemetry_instrumentation_fastapi-0.47b0-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting opentelemetry-instrumentation-asgi==0.47b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Downloading opentelemetry_instrumentation_asgi-0.47b0-py3-none-any.whl.metadata (2.0 kB)\n",
      "Collecting opentelemetry-instrumentation==0.47b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Downloading opentelemetry_instrumentation-0.47b0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting opentelemetry-semantic-conventions==0.47b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Downloading opentelemetry_semantic_conventions-0.47b0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting opentelemetry-util-http==0.47b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Downloading opentelemetry_util_http-0.47b0-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting opentelemetry-api>=1.2.0 (from chromadb)\n",
      "  Downloading opentelemetry_api-1.26.0-py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb)\n",
      "  Downloading opentelemetry_instrumentation_fastapi-0.46b0-py3-none-any.whl.metadata (2.0 kB)\n",
      "Collecting opentelemetry-instrumentation-asgi==0.46b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Downloading opentelemetry_instrumentation_asgi-0.46b0-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting opentelemetry-instrumentation==0.46b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Downloading opentelemetry_instrumentation-0.46b0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.46b0 in /opt/conda/lib/python3.10/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.46b0)\n",
      "Collecting opentelemetry-util-http==0.46b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Downloading opentelemetry_util_http-0.46b0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting monotonic>=1.5 (from posthog>=2.4.0->chromadb)\n",
      "  Downloading monotonic-1.6-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting backoff>=1.10.0 (from posthog>=2.4.0->chromadb)\n",
      "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from pydantic>=1.9->chromadb) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /opt/conda/lib/python3.10/site-packages (from pydantic>=1.9->chromadb) (2.23.4)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich>=10.11.0->chromadb) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich>=10.11.0->chromadb) (2.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /opt/conda/lib/python3.10/site-packages (from tokenizers>=0.13.2->chromadb) (0.25.1)\n",
      "Requirement already satisfied: click>=8.0.0 in /opt/conda/lib/python3.10/site-packages (from typer>=0.9.0->chromadb) (8.1.7)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /opt/conda/lib/python3.10/site-packages (from typer>=0.9.0->chromadb) (1.5.4)\n",
      "Requirement already satisfied: httptools>=0.5.0 in /opt/conda/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.6.1)\n",
      "Requirement already satisfied: python-dotenv>=0.13 in /opt/conda/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.0.1)\n",
      "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /opt/conda/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.19.0)\n",
      "Requirement already satisfied: watchfiles>=0.13 in /opt/conda/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.22.0)\n",
      "Requirement already satisfied: websockets>=10.4 in /opt/conda/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (12.0)\n",
      "Requirement already satisfied: dnspython>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from email_validator>=2.0.0->fastapi>=0.95.2->chromadb) (2.6.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.2.4)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.15.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2024.6.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.10/site-packages (from importlib-metadata<=7.1,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.19.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2>=2.11.2->fastapi>=0.95.2->chromadb) (2.1.5)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->kubernetes>=28.1.0->chromadb) (3.3.2)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /opt/conda/lib/python3.10/site-packages (from anyio->httpx>=0.27.0->chromadb) (1.2.0)\n",
      "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb)\n",
      "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.6.0)\n",
      "Downloading chromadb-0.5.18-py3-none-any.whl (615 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m615.5/615.5 kB\u001b[0m \u001b[31m25.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading chroma_hnswlib-0.7.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m59.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading bcrypt-4.2.0-cp39-abi3-manylinux_2_28_x86_64.whl (273 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m273.8/273.8 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading build-1.2.2.post1-py3-none-any.whl (22 kB)\n",
      "Downloading kubernetes-31.0.0-py2.py3-none-any.whl (1.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m56.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading mmh3-5.0.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (93 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.2/93.2 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading onnxruntime-1.20.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (13.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m82.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading opentelemetry_instrumentation_fastapi-0.46b0-py3-none-any.whl (11 kB)\n",
      "Downloading opentelemetry_instrumentation-0.46b0-py3-none-any.whl (29 kB)\n",
      "Downloading opentelemetry_instrumentation_asgi-0.46b0-py3-none-any.whl (14 kB)\n",
      "Downloading opentelemetry_util_http-0.46b0-py3-none-any.whl (6.9 kB)\n",
      "Downloading posthog-3.7.0-py2.py3-none-any.whl (54 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.4/54.4 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
      "Downloading durationpy-0.9-py3-none-any.whl (3.5 kB)\n",
      "Downloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
      "Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyproject_hooks-1.2.0-py3-none-any.whl (10 kB)\n",
      "Downloading asgiref-3.8.1-py3-none-any.whl (23 kB)\n",
      "Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: pypika\n",
      "  Building wheel for pypika (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pypika: filename=PyPika-0.48.9-py2.py3-none-any.whl size=53725 sha256=5a73ab42870ff5d173284add16766cb66271b0ab23717c639865f32244289257\n",
      "  Stored in directory: /root/.cache/pip/wheels/e1/26/51/d0bffb3d2fd82256676d7ad3003faea3bd6dddc9577af665f4\n",
      "Successfully built pypika\n",
      "Installing collected packages: pypika, monotonic, durationpy, pyproject_hooks, opentelemetry-util-http, mmh3, humanfriendly, chroma-hnswlib, bcrypt, backoff, asgiref, posthog, coloredlogs, build, opentelemetry-instrumentation, onnxruntime, kubernetes, opentelemetry-instrumentation-asgi, opentelemetry-instrumentation-fastapi, chromadb\n",
      "  Attempting uninstall: kubernetes\n",
      "    Found existing installation: kubernetes 26.1.0\n",
      "    Uninstalling kubernetes-26.1.0:\n",
      "      Successfully uninstalled kubernetes-26.1.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "kfp 2.5.0 requires google-cloud-storage<3,>=2.2.1, but you have google-cloud-storage 1.44.0 which is incompatible.\n",
      "kfp 2.5.0 requires kubernetes<27,>=8.0.0, but you have kubernetes 31.0.0 which is incompatible.\n",
      "kfp 2.5.0 requires requests-toolbelt<1,>=0.8.0, but you have requests-toolbelt 1.0.0 which is incompatible.\n",
      "kfp 2.5.0 requires urllib3<2.0.0, but you have urllib3 2.2.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed asgiref-3.8.1 backoff-2.2.1 bcrypt-4.2.0 build-1.2.2.post1 chroma-hnswlib-0.7.6 chromadb-0.5.18 coloredlogs-15.0.1 durationpy-0.9 humanfriendly-10.0 kubernetes-31.0.0 mmh3-5.0.1 monotonic-1.6 onnxruntime-1.20.0 opentelemetry-instrumentation-0.46b0 opentelemetry-instrumentation-asgi-0.46b0 opentelemetry-instrumentation-fastapi-0.46b0 opentelemetry-util-http-0.46b0 posthog-3.7.0 pypika-0.48.9 pyproject_hooks-1.2.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T17:33:36.444625Z",
     "iopub.status.busy": "2024-11-18T17:33:36.444187Z",
     "iopub.status.idle": "2024-11-18T17:33:36.451179Z",
     "shell.execute_reply": "2024-11-18T17:33:36.449671Z",
     "shell.execute_reply.started": "2024-11-18T17:33:36.444582Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"COHERE_API_KEY\"] = \"Your-api-key\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T17:33:36.453500Z",
     "iopub.status.busy": "2024-11-18T17:33:36.453005Z",
     "iopub.status.idle": "2024-11-18T17:33:55.672921Z",
     "shell.execute_reply": "2024-11-18T17:33:55.671511Z",
     "shell.execute_reply.started": "2024-11-18T17:33:36.453446Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Import the os package\n",
    "import os\n",
    "\n",
    "# Import the glob package\n",
    "import glob\n",
    "\n",
    "\n",
    "# Import the yt_dlp package as youtube_dl\n",
    "import yt_dlp as youtube_dl\n",
    "\n",
    "# Import DownloadError from yt_dlp\n",
    "from yt_dlp import DownloadError\n",
    "\n",
    "# Import DocArray\n",
    "import docarray\n",
    "\n",
    "import tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T17:33:55.678110Z",
     "iopub.status.busy": "2024-11-18T17:33:55.676654Z",
     "iopub.status.idle": "2024-11-18T17:33:55.684783Z",
     "shell.execute_reply": "2024-11-18T17:33:55.683217Z",
     "shell.execute_reply.started": "2024-11-18T17:33:55.678063Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# An example YouTube tutorial video\n",
    "youtube_url = \"https://www.youtube.com/watch?v=oVtlp72f9NQ\"\n",
    "\n",
    "# Directory to store the downloaded video\n",
    "output_dir = \"/files/audio/\"\n",
    "\n",
    "# Config for youtube-dl\n",
    "ydl_config = {\n",
    "    \"format\": \"bestaudio/best\",\n",
    "    \"postprocessors\": [\n",
    "        {\n",
    "            \"key\": \"FFmpegExtractAudio\",\n",
    "            \"preferredcodec\": \"mp3\",\n",
    "            \"preferredquality\": \"192\",\n",
    "        }\n",
    "    ],\n",
    "    \"outtmpl\": os.path.join(output_dir, \"%(title)s.%(ext)s\"),\n",
    "    \"verbose\": True\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T17:33:55.687326Z",
     "iopub.status.busy": "2024-11-18T17:33:55.686730Z",
     "iopub.status.idle": "2024-11-18T17:34:10.244330Z",
     "shell.execute_reply": "2024-11-18T17:34:10.242970Z",
     "shell.execute_reply.started": "2024-11-18T17:33:55.687266Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[debug] Encodings: locale UTF-8, fs utf-8, pref UTF-8, out UTF-8 (No ANSI), error UTF-8 (No ANSI), screen UTF-8 (No ANSI)\n",
      "[debug] yt-dlp version stable@2024.04.09 from yt-dlp/yt-dlp [ff0779267] (pip) API\n",
      "[debug] params: {'format': 'bestaudio/best', 'postprocessors': [{'key': 'FFmpegExtractAudio', 'preferredcodec': 'mp3', 'preferredquality': '192'}], 'outtmpl': '/files/audio/%(title)s.%(ext)s', 'verbose': True, 'compat_opts': set(), 'http_headers': {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/93.0.4577.63 Safari/537.36', 'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8', 'Accept-Language': 'en-us,en;q=0.5', 'Sec-Fetch-Mode': 'navigate'}}\n",
      "[debug] Python 3.10.14 (CPython x86_64 64bit) - Linux-6.6.56+-x86_64-with-glibc2.31 (OpenSSL 3.3.2 3 Sep 2024, glibc 2.31)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading video from https://www.youtube.com/watch?v=oVtlp72f9NQ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[debug] exe versions: ffmpeg 4.2.7, ffprobe 4.2.7\n",
      "[debug] Optional libraries: Cryptodome-3.21.0, brotli-None, certifi-2024.08.30, mutagen-1.47.0, requests-2.32.3, secretstorage-3.3.3, sqlite3-3.46.1, urllib3-2.2.3, websockets-12.0\n",
      "[debug] Proxy map: {}\n",
      "[debug] Request Handlers: urllib, requests, websockets\n",
      "[debug] Loaded 1810 extractors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[youtube] Extracting URL: https://www.youtube.com/watch?v=oVtlp72f9NQ\n",
      "[youtube] oVtlp72f9NQ: Downloading webpage\n",
      "[youtube] oVtlp72f9NQ: Downloading ios player API JSON\n",
      "[youtube] oVtlp72f9NQ: Downloading android player API JSON\n",
      "[youtube] oVtlp72f9NQ: Downloading player 2d24ba15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: [youtube] oVtlp72f9NQ: nsig extraction failed: You may experience throttling for some formats\n",
      "         n = mvZx7otGrEbvFSqk0 ; player = https://www.youtube.com/s/player/2d24ba15/player_ias.vflset/en_US/base.js\n",
      "[debug] [youtube] Unable to extract nsig function code (caused by RegexNotFoundError('Unable to extract Initial JS player n function name; please report this issue on  https://github.com/yt-dlp/yt-dlp/issues?q= , filling out the appropriate issue template. Confirm you are on the latest version using  yt-dlp -U')); please report this issue on  https://github.com/yt-dlp/yt-dlp/issues?q= , filling out the appropriate issue template. Confirm you are on the latest version using  yt-dlp -U\n",
      "WARNING: [youtube] oVtlp72f9NQ: nsig extraction failed: You may experience throttling for some formats\n",
      "         n = Kp9r6VvKbBQBRSTag ; player = https://www.youtube.com/s/player/2d24ba15/player_ias.vflset/en_US/base.js\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[youtube] oVtlp72f9NQ: Downloading m3u8 information\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[debug] Sort order given by extractor: quality, res, fps, hdr:12, source, vcodec:vp9.2, channels, acodec, lang, proto\n",
      "[debug] Formats sorted by: hasvid, ie_pref, quality, res, fps, hdr:12(7), source, vcodec:vp9.2(10), channels, acodec, lang, proto, size, br, asr, vext, aext, hasaud, id\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] oVtlp72f9NQ: Downloading 1 format(s): 140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[debug] Invoking http downloader on \"https://rr5---sn-ntq7yney.googlevideo.com/videoplayback?expire=1731972838&ei=hno7Z-kqq9rctQ_tucVA&ip=34.151.105.39&id=o-AMr-hP8OYqz_zY8TsgF7Z38dE1yvV7BNma_1YTHZLBZc&itag=140&source=youtube&requiressl=yes&xpc=EgVo2aDSNQ%3D%3D&met=1731951238%2C&mh=Ea&mm=31%2C29&mn=sn-ntq7yney%2Csn-ntqe6n7k&ms=au%2Crdu&mv=m&mvi=5&pl=20&rms=au%2Cau&spc=qtApAY1N_j0y5MjhREsD39s1W5FuQzZBd8O7hBxODnlThrk&vprv=1&svpuc=1&mime=audio%2Fmp4&rqh=1&gir=yes&clen=6461322&dur=399.197&lmt=1729786157865057&mt=1731950725&fvip=2&keepalive=yes&fexp=51299154%2C51312688%2C51326932&c=IOS&txp=5318224&sparams=expire%2Cei%2Cip%2Cid%2Citag%2Csource%2Crequiressl%2Cxpc%2Cspc%2Cvprv%2Csvpuc%2Cmime%2Crqh%2Cgir%2Cclen%2Cdur%2Clmt&sig=AJfQdSswRAIgMVzl-9AJYKvHua8PxFvT4GXzKPAIke0HGz2JYSBu69QCIALZP8bDDS9pl0hm_sSDv31zm5fYAcJ_SKj-qThI9UG7&lsparams=met%2Cmh%2Cmm%2Cmn%2Cms%2Cmv%2Cmvi%2Cpl%2Crms&lsig=AGluJ3MwRgIhAMZvN16SFPJPLEieeE4bhr7griOWz2qHWKm_AEfLUGqvAiEAoYDsrprOEdqHGp0ky388Zl2vFtlhUWNxR9mdz61A_yw%3D\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[download] Destination: /files/audio/How to use Retrieval Augmented Generation (RAG).m4a\n",
      "[download] 100% of    6.16MiB in 00:00:02 at 2.93MiB/s   \n",
      "[FixupM4a] Correcting container of \"/files/audio/How to use Retrieval Augmented Generation (RAG).m4a\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[debug] ffmpeg command line: ffmpeg -y -loglevel repeat+info -i 'file:/files/audio/How to use Retrieval Augmented Generation (RAG).m4a' -map 0 -dn -ignore_unknown -c copy -f mp4 -movflags +faststart 'file:/files/audio/How to use Retrieval Augmented Generation (RAG).temp.m4a'\n",
      "[debug] ffmpeg command line: ffprobe -show_streams 'file:/files/audio/How to use Retrieval Augmented Generation (RAG).m4a'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ExtractAudio] Destination: /files/audio/How to use Retrieval Augmented Generation (RAG).mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[debug] ffmpeg command line: ffmpeg -y -loglevel repeat+info -i 'file:/files/audio/How to use Retrieval Augmented Generation (RAG).m4a' -vn -acodec libmp3lame -b:a 192.0k -movflags +faststart 'file:/files/audio/How to use Retrieval Augmented Generation (RAG).mp3'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleting original file /files/audio/How to use Retrieval Augmented Generation (RAG).m4a (pass -k to keep)\n"
     ]
    }
   ],
   "source": [
    "# Check if the output directory exists, if not create it\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "# Print a message indicating which video is being downloaded\n",
    "print(f\"Downloading video from {youtube_url}\")\n",
    "\n",
    "# Try to download the video using the specified configuration\n",
    "# If a DownloadError occurs, attempt to download the video again\n",
    "try:\n",
    "    with youtube_dl.YoutubeDL(ydl_config) as ydl:\n",
    "        ydl.download([youtube_url])\n",
    "except DownloadError:\n",
    "    with youtube_dl.YoutubeDL(ydl_config) as ydl:\n",
    "        ydl.download([youtube_url])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T17:34:10.246795Z",
     "iopub.status.busy": "2024-11-18T17:34:10.246284Z",
     "iopub.status.idle": "2024-11-18T17:34:10.255415Z",
     "shell.execute_reply": "2024-11-18T17:34:10.253971Z",
     "shell.execute_reply.started": "2024-11-18T17:34:10.246739Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/files/audio/How to use Retrieval Augmented Generation (RAG).mp3\n"
     ]
    }
   ],
   "source": [
    "# Find the audio file in the output directory\n",
    "\n",
    "# Find all the audio files in the output directory\n",
    "audio_files = glob.glob(os.path.join(output_dir, \"*.mp3\"))\n",
    "\n",
    "# Select the first audio file in the list\n",
    "audio_filename = audio_files[0]\n",
    "\n",
    "# Print the name of the selected audio file\n",
    "print(audio_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T17:34:10.257561Z",
     "iopub.status.busy": "2024-11-18T17:34:10.257158Z",
     "iopub.status.idle": "2024-11-18T17:35:28.490518Z",
     "shell.execute_reply": "2024-11-18T17:35:28.489300Z",
     "shell.execute_reply.started": "2024-11-18T17:34:10.257517Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 139M/139M [00:01<00:00, 88.3MiB/s]\n",
      "/opt/conda/lib/python3.10/site-packages/whisper/__init__.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(fp, map_location=device)\n",
      "/opt/conda/lib/python3.10/site-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcription:\n",
      " Music Greetings, Aja. Now that we've discussed choosing a model and embedding, what's our next topic in the series? I thought it would be good to dig into Rags, so we can see why people create embeddings in the first place and how you can help the LLM you selected generate better results. So for all of you falling along, Rags is essentially retrieval Augmented Generation. So it's Augmented Generation with something you retrieve and cut. Not, not, no. Okay, hopefully we can go into more detail and break down the jargon and give folks tips for creating straightforward Rags applications. That's fair. So first off, what exactly is Rags and what's the purpose of it? Rags is just an architectural approach to building AI applications and services. So Rags is just a common AI architecture in the same way that three tier app is a common WebRag. Right? Yep. And the goal of Rags is to improve what the LLM generates by grounding it in data that's relevant and known to be accurate. Exactly. And now that we've established why we would use Rags and what it is, let's dig into the data flow of a typical Rags application. This is probably going to be easier if we have an example, right? Yeah. So let's say that we're building something for maybe a local government website. What we're going to do is help people find information about various things that are going on like jury duty or maybe even pet licensing. Okay. So to start with, Rags apps have a pre-processing step where you need to create the embeddings for the data you want to use for grounding your responses. Our videos on embeddings can help you understand the options here and the things you need to consider. Okay. And for this chatbot, we probably want to chunk and create embeddings for all maybe the different pages on our website and maybe even for additional things like forms and brochures or images that we have. And we should store all that data with their embeddings in a vector database. Okay. So with that pre-processing step out of the way, let's walk through what happens when a user asks our chatbot a question. First, we're going to take the user's question and we're going to call that a prompt and we're going to use the same embedding model we used in our pre-processing step to generate an embedding or a vector of that user's question. Then we're going to use that embedding we just generated to find some number of related pieces of data in our data store using a similarity algorithm. I think we talked about this in our embedding videos, but just to recap, we used the embeddings model to make sure that all the similar data ends up with similar vectors. And that makes it easy for a vector database to find all the related info. Exactly. Now, once we've found that related info, we're going to add it to the original prompt, augmenting what the user gave us. That's the A and Rag. Usually, you'll also add some text to tell the LLM what to do with that related data. For example, base your answer to the user's question on the following documents. Just to clarify, since it confuses folks, when we retrieve the related data, are we retrieving the actual vector of the embedding? Or are we retrieving the original piece of data that we made the embedding off of? Great question. This confuses a lot of people. You use the embedding, the bigger array of numbers, to find similar pieces of data. But the vector database returns the original data in the original format. So that might be text, or a photo, or video, or audio. I think that makes sense. And so then the original human readable data that we got is what we're going to add to our LLM and give that to the LLM in order to help generate its answer. Yep. So back to our walkthrough. Once we've added the relevant data or context to our prompt, we can send it to an LLM like Gemini. Does that have to be the same model that we used though when we generate our embedding? No. As we talked about in the embedding videos, it doesn't have to be. And in many cases, it won't be. So then what do we do with what Gemini generates the returns to us if Gemini was our LLM in this example? And the simplest case? We just pass Gemini's response to the user. Since Gemini's response should contain an answer to the question the user asked. Okay. So let's make sure I can summarize this right. We generated embeddings with all of our data. Then when our user asked a question, I think a few things happened. First, we generated an embedding of what the user's question was. Second, we used that embedding to find relevant data in our vector database. Third, we took all that relevant data and we added that to the prompt that we sent to the LLM to get a response. And then last or fourth, we sent that response back to our user with the answer. Yep. That's it. That is the data flow for the most basic rag application. Okay. But let's say I'm not happy with the very simple path, which I should be, right? What are some of the common mistakes that people make or what are some of the common things I can do to improve my rag performance? So first part, the embeddings are the heart of a rag system. If your embeddings aren't appropriate for your data, you won't be able to retrieve relevant data for the LLM to use to generate a response. So I think here, right, it's really about the concepts of embedding dimensionality, maybe the chunk size and the chunk overlap of my embeddings. Those things are really important to thinking about how I get the most performance out of the data that I give rag. Another thing to think about is the quality of the user's initial question. Since we're creating an embedding vector from that, if the quality of the question is poorly formed or has a lot of misspellings, that may impact the quality of the results. Some folks have had good luck with sending that initial question, that initial prompt to an LLM and asking the LLM to improve it before they proceed with the normal rag workflow. That's cool. And I also think, as I think through these things, what data I'm going to put in the vector database at first also could change the results they get back. So I may want to have folks actually write up specific answers to common questions and put those into the database so that way I get the highest quality response back. Exactly. And you can also try varying the number of relevant pieces of data you return from the database that you put into your call to the LLM. With today's large context windows, it usually makes sense to include more relevant data, but you should check how changing the amount of information you add changes the quality of the responses. That's interesting. I think two million context token windows probably comes in the play here in some sense. Okay, so we've talked about how we can do all these cool things with rag. We've explained how it works and obviously we've done a quick walkthrough. By the way, we have a code lab and a jumpstart solution you could deploy to try rag out and the details are in the comments below. With that, this is Ajan Jason with real terms for AI. Happy Promising everyone. Thanks for watching.\n"
     ]
    }
   ],
   "source": [
    "import whisper\n",
    "\n",
    "# Load the Whisper model\n",
    "model = whisper.load_model(\"base\")  # Options: \"tiny\", \"base\", \"small\", \"medium\", \"large\"\n",
    "\n",
    "# Transcribe the MP3 file\n",
    "result = model.transcribe(audio_filename)\n",
    "\n",
    "# Print the transcription\n",
    "print(\"Transcription:\")\n",
    "print(result['text'])\n",
    "transcript=result['text']\n",
    "output_file = \"files/transcripts/transcript.txt\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T17:35:28.492798Z",
     "iopub.status.busy": "2024-11-18T17:35:28.492321Z",
     "iopub.status.idle": "2024-11-18T17:35:28.500629Z",
     "shell.execute_reply": "2024-11-18T17:35:28.499118Z",
     "shell.execute_reply.started": "2024-11-18T17:35:28.492755Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Create the directory for the output file if it doesn't exist\n",
    "os.makedirs(os.path.dirname(output_file), exist_ok=True)\n",
    "\n",
    "# Write the transcript to the output file\n",
    "with open(output_file, \"w\") as file:\n",
    "    file.write(transcript)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T17:35:28.502748Z",
     "iopub.status.busy": "2024-11-18T17:35:28.502281Z",
     "iopub.status.idle": "2024-11-18T17:35:29.586639Z",
     "shell.execute_reply": "2024-11-18T17:35:29.585420Z",
     "shell.execute_reply.started": "2024-11-18T17:35:28.502707Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# From the langchain.document_loaders module, import TextLoader\n",
    "from langchain.document_loaders import TextLoader\n",
    "\n",
    "# Create a `TextLoader`, passing the directory of the transcripts. Assign to `loader`.\n",
    "loader = TextLoader(\"./files/transcripts/transcript.txt\")\n",
    "\n",
    "# Use the TextLoader to load the documents. Assign to docs.\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T17:35:29.588505Z",
     "iopub.status.busy": "2024-11-18T17:35:29.588137Z",
     "iopub.status.idle": "2024-11-18T17:35:29.597177Z",
     "shell.execute_reply": "2024-11-18T17:35:29.595941Z",
     "shell.execute_reply.started": "2024-11-18T17:35:29.588469Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" Music Greetings, Aja. Now that we've discussed choosing a model and embedding, what's our next topic in the series? I thought it would be good to dig into Rags, so we can see why people create embeddings in the first place and how you can help the LLM you selected generate better results. So for all of you falling along, Rags is essentially retrieval Augmented Generation. So it's Augmented Generation with something you retrieve and cut. Not, not, no. Okay, hopefully we can go into more detail and break down the jargon and give folks tips for creating straightforward Rags applications. That's fair. So first off, what exactly is Rags and what's the purpose of it? Rags is just an architectural approach to building AI applications and services. So Rags is just a common AI architecture in the same way that three tier app is a common WebRag. Right? Yep. And the goal of Rags is to improve what the LLM generates by grounding it in data that's relevant and known to be accurate. Exactly. And now that we've established why we would use Rags and what it is, let's dig into the data flow of a typical Rags application. This is probably going to be easier if we have an example, right? Yeah. So let's say that we're building something for maybe a local government website. What we're going to do is help people find information about various things that are going on like jury duty or maybe even pet licensing. Okay. So to start with, Rags apps have a pre-processing step where you need to create the embeddings for the data you want to use for grounding your responses. Our videos on embeddings can help you understand the options here and the things you need to consider. Okay. And for this chatbot, we probably want to chunk and create embeddings for all maybe the different pages on our website and maybe even for additional things like forms and brochures or images that we have. And we should store all that data with their embeddings in a vector database. Okay. So with that pre-processing step out of the way, let's walk through what happens when a user asks our chatbot a question. First, we're going to take the user's question and we're going to call that a prompt and we're going to use the same embedding model we used in our pre-processing step to generate an embedding or a vector of that user's question. Then we're going to use that embedding we just generated to find some number of related pieces of data in our data store using a similarity algorithm. I think we talked about this in our embedding videos, but just to recap, we used the embeddings model to make sure that all the similar data ends up with similar vectors. And that makes it easy for a vector database to find all the related info. Exactly. Now, once we've found that related info, we're going to add it to the original prompt, augmenting what the user gave us. That's the A and Rag. Usually, you'll also add some text to tell the LLM what to do with that related data. For example, base your answer to the user's question on the following documents. Just to clarify, since it confuses folks, when we retrieve the related data, are we retrieving the actual vector of the embedding? Or are we retrieving the original piece of data that we made the embedding off of? Great question. This confuses a lot of people. You use the embedding, the bigger array of numbers, to find similar pieces of data. But the vector database returns the original data in the original format. So that might be text, or a photo, or video, or audio. I think that makes sense. And so then the original human readable data that we got is what we're going to add to our LLM and give that to the LLM in order to help generate its answer. Yep. So back to our walkthrough. Once we've added the relevant data or context to our prompt, we can send it to an LLM like Gemini. Does that have to be the same model that we used though when we generate our embedding? No. As we talked about in the embedding videos, it doesn't have to be. And in many cases, it won't be. So then what do we do with what Gemini generates the returns to us if Gemini was our LLM in this example? And the simplest case? We just pass Gemini's response to the user. Since Gemini's response should contain an answer to the question the user asked. Okay. So let's make sure I can summarize this right. We generated embeddings with all of our data. Then when our user asked a question, I think a few things happened. First, we generated an embedding of what the user's question was. Second, we used that embedding to find relevant data in our vector database. Third, we took all that relevant data and we added that to the prompt that we sent to the LLM to get a response. And then last or fourth, we sent that response back to our user with the answer. Yep. That's it. That is the data flow for the most basic rag application. Okay. But let's say I'm not happy with the very simple path, which I should be, right? What are some of the common mistakes that people make or what are some of the common things I can do to improve my rag performance? So first part, the embeddings are the heart of a rag system. If your embeddings aren't appropriate for your data, you won't be able to retrieve relevant data for the LLM to use to generate a response. So I think here, right, it's really about the concepts of embedding dimensionality, maybe the chunk size and the chunk overlap of my embeddings. Those things are really important to thinking about how I get the most performance out of the data that I give rag. Another thing to think about is the quality of the user's initial question. Since we're creating an embedding vector from that, if the quality of the question is poorly formed or has a lot of misspellings, that may impact the quality of the results. Some folks have had good luck with sending that initial question, that initial prompt to an LLM and asking the LLM to improve it before they proceed with the normal rag workflow. That's cool. And I also think, as I think through these things, what data I'm going to put in the vector database at first also could change the results they get back. So I may want to have folks actually write up specific answers to common questions and put those into the database so that way I get the highest quality response back. Exactly. And you can also try varying the number of relevant pieces of data you return from the database that you put into your call to the LLM. With today's large context windows, it usually makes sense to include more relevant data, but you should check how changing the amount of information you add changes the quality of the responses. That's interesting. I think two million context token windows probably comes in the play here in some sense. Okay, so we've talked about how we can do all these cool things with rag. We've explained how it works and obviously we've done a quick walkthrough. By the way, we have a code lab and a jumpstart solution you could deploy to try rag out and the details are in the comments below. With that, this is Ajan Jason with real terms for AI. Happy Promising everyone. Thanks for watching.\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T17:35:29.599748Z",
     "iopub.status.busy": "2024-11-18T17:35:29.599044Z",
     "iopub.status.idle": "2024-11-18T17:35:40.211661Z",
     "shell.execute_reply": "2024-11-18T17:35:40.209937Z",
     "shell.execute_reply.started": "2024-11-18T17:35:29.599697Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The video is a tutorial on Rags, or retrieval Augmented Generation, which is an architectural approach to building AI applications and services. The video explains how Rags works and how it can be used to improve the performance of an LLM by grounding it in relevant and accurate data. The video also provides a walkthrough of a typical Rags application and discusses common mistakes and ways to improve performance.\n"
     ]
    }
   ],
   "source": [
    "from langchain_cohere import ChatCohere, CohereEmbeddings, CohereRerank, CohereRagRetriever\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "\n",
    "user_query =  \"what's the context of the video ?\"\n",
    "\n",
    "llm = ChatCohere(cohere_api_key=\"nh9NTE38YIwFnepucp50ApOyveMqm67f1chNROqq\",              \n",
    "                 model=\"command-r-plus-08-2024\",\n",
    "                 temperature=0)\n",
    "\n",
    "embeddings = CohereEmbeddings(cohere_api_key=\"nh9NTE38YIwFnepucp50ApOyveMqm67f1chNROqq\",\n",
    "                              model=\"embed-english-v3.0\")\n",
    "\n",
    "# Load text files and split into chunks, you can also use data gathered elsewhere in your application\n",
    "#raw_documents = WebBaseLoader(\"https://docs.cohere.com/docs/cohere-toolkit\").load()\n",
    "\n",
    "#text_splitter = CharacterTextSplitter(chunk_size=500, chunk_overlap=0)\n",
    "#documents = text_splitter.split_documents(raw_documents)\n",
    "# Create a vector store from the documents\n",
    "db = Chroma.from_documents(docs, embeddings)\n",
    "input_docs = db.as_retriever().invoke(user_query)\n",
    "\n",
    "# Create the cohere rag retriever using the chat model \n",
    "rag = CohereRagRetriever(llm=llm)\n",
    "docc = rag.invoke(\n",
    "    user_query,\n",
    "    documents=input_docs,\n",
    ")\n",
    "print(docc[-1].page_content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T17:35:40.214648Z",
     "iopub.status.busy": "2024-11-18T17:35:40.213562Z",
     "iopub.status.idle": "2024-11-18T17:35:45.646606Z",
     "shell.execute_reply": "2024-11-18T17:35:45.645289Z",
     "shell.execute_reply.started": "2024-11-18T17:35:40.214591Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rags is an architectural approach to building AI applications and services. It is a common AI architecture, in the same way that three tier app is a common WebRag. The goal of Rags is to improve what the LLM generates by grounding it in data that's relevant and known to be accurate.\n"
     ]
    }
   ],
   "source": [
    "user_query =  \"what exactly is Rags ?\"\n",
    "doce = rag.invoke(\n",
    "    user_query,\n",
    "    documents=input_docs,\n",
    ")\n",
    "print(doce[-1].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T17:40:42.777562Z",
     "iopub.status.busy": "2024-11-18T17:40:42.777121Z",
     "iopub.status.idle": "2024-11-18T17:40:44.546693Z",
     "shell.execute_reply": "2024-11-18T17:40:44.545334Z",
     "shell.execute_reply.started": "2024-11-18T17:40:42.777527Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ajan Jason is speaking.\n"
     ]
    }
   ],
   "source": [
    "user_query =  \"who is speaking ?\"\n",
    "doce = rag.invoke(\n",
    "    user_query,\n",
    "    documents=input_docs,\n",
    ")\n",
    "print(doce[-1].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T17:41:10.567551Z",
     "iopub.status.busy": "2024-11-18T17:41:10.567149Z",
     "iopub.status.idle": "2024-11-18T17:41:13.041327Z",
     "shell.execute_reply": "2024-11-18T17:41:13.040014Z",
     "shell.execute_reply.started": "2024-11-18T17:41:10.567518Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm sorry, I couldn't find any information about CNN. Can you please clarify what you're looking for?\n"
     ]
    }
   ],
   "source": [
    "user_query =  \"what's CNN ?\"\n",
    "doce = rag.invoke(\n",
    "    user_query,\n",
    "    documents=input_docs,\n",
    ")\n",
    "print(doce[-1].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T17:41:39.365636Z",
     "iopub.status.busy": "2024-11-18T17:41:39.365206Z",
     "iopub.status.idle": "2024-11-18T17:41:50.334694Z",
     "shell.execute_reply": "2024-11-18T17:41:50.332723Z",
     "shell.execute_reply.started": "2024-11-18T17:41:39.365602Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This video explains the concept of Rags, or retrieval Augmented Generation, which is an architectural approach to building AI applications and services. The goal of Rags is to improve what the LLM generates by grounding it in data that's relevant and known to be accurate. The video then goes on to explain the data flow of a typical Rags application, using the example of a local government website. It explains how Rags apps have a pre-processing step where you need to create the embeddings for the data you want to use for grounding your responses. The video then explains how to use the same embedding model to generate an embedding or a vector of the user's question, and then use that embedding to find related pieces of data in the data store using a similarity algorithm. The video then explains how to add the related data to the original prompt, augmenting what the user gave us. The video then explains how to send the prompt to an LLM like Gemini, and then pass Gemini's response to the user. The video then explains how to improve rag performance by considering the concepts of embedding dimensionality, chunk size and chunk overlap of embeddings, as well as the quality of the user's initial question.\n"
     ]
    }
   ],
   "source": [
    "user_query =  \"Summarize the video content in few lines ?\"\n",
    "doce = rag.invoke(\n",
    "    user_query,\n",
    "    documents=input_docs,\n",
    ")\n",
    "print(doce[-1].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 30786,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
